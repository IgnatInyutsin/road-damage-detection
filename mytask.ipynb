{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgnatInyutsin/road-damage-detection/blob/main/mytask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2DsDp3Zcqji"
      },
      "source": [
        "# Конфиг"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FQZf5dB7b1aw"
      },
      "outputs": [],
      "source": [
        "# подключенные дата сеты\n",
        "DATASET_PATHES = [\"/content/drive/MyDrive/Potholes Dataset/Dataset 1 (Simplex)/\"]\n",
        "# с какого изображения собирать данные\n",
        "DATASET_START_INDEX  = 0\n",
        "# сколько данных собирать одного типа с каждого датасета\n",
        "DATASET_LIMIT = 100\n",
        "\n",
        "EPOCHS = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIAhf7Y1cxMW"
      },
      "source": [
        "# Вспомогательные функции"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gfoBAltCc3_T"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# нормализует изображенние\n",
        "def normalize(img_path):\n",
        "  # gray\n",
        "  img = cv2.imread(img_path, 0)\n",
        "  # downscale\n",
        "  height, width = img.shape[:2]\n",
        "  img = cv2.resize(img, (width//5, height//5))\n",
        "  \n",
        "  return img\n",
        "\n",
        "# пара тест-значение для датасета\n",
        "def generate_pair(line=[], pre_path=\"\"):\n",
        "  # собираем путь к файлу\n",
        "  path = pre_path\n",
        "  i = 0\n",
        "  while not line[i].isnumeric():\n",
        "    path += line[i] + \" \"\n",
        "    i+=1\n",
        "  path = path[:-1].replace(\"\\\\\", \"/\").replace(\".bmp\", \".JPG\")\n",
        "\n",
        "  # нормализуем изображение\n",
        "  try:\n",
        "    img = normalize(path)\n",
        "  except: \n",
        "    return None\n",
        "  \n",
        "  height, width = img.shape[:2]\n",
        "\n",
        "  # маска (выходной слой)\n",
        "  mask = np.zeros((height, width))\n",
        "  # обводим ямы на маске\n",
        "  i += 1\n",
        "  while i < len(line):\n",
        "    '''\n",
        "    В файле каждому прямоугольнику сопоставлено 4 значения:\n",
        "    1, 2 - координаты верхнего левого угла\n",
        "    3 - длина стороны, сонаправлений с осью x\n",
        "    4 - длина стороны, сонаправленной с осью y\n",
        "    '''\n",
        "    cv2.rectangle(mask, (int(line[i])//5, int(line[i+1])//5), \n",
        "                  ((int(line[i])+int(line[i+2]))//5, (int(line[i+1])+int(line[i+3]))//5),\n",
        "                  (255, 255, 255),\n",
        "                  -1)\n",
        "    i += 4\n",
        "\n",
        "    return (img, mask,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZXNYbvfeX3Z"
      },
      "source": [
        "# Парсинг датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgIcI9gZefdu"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "x_train, y_train = [], []\n",
        "\n",
        "for path in DATASET_PATHES:\n",
        "  '''\n",
        "  k - ограничитель количество итераций по файлам\n",
        "  '''\n",
        "  k = 0\n",
        "\n",
        "  # собираем позитивные данные\n",
        "  os.chdir(path)\n",
        "  with open(\"simpleTrainFullPhotosSortedFullAnnotations.txt\") as file:\n",
        "    line = file.readline().split()\n",
        "\n",
        "    while k < DATASET_START_INDEX:\n",
        "      # пропускаем значения то индекса\n",
        "      k += 1\n",
        "      line = file.readline().split()\n",
        "\n",
        "    # сами итерации\n",
        "    while line and k < DATASET_LIMIT + DATASET_START_INDEX:\n",
        "      k += 1\n",
        "\n",
        "      try:\n",
        "        x, y = generate_pair(line=line, pre_path=path)\n",
        "      except: \n",
        "        continue\n",
        "      \n",
        "      x_train.append(x)\n",
        "      y_train.append(y)\n",
        "\n",
        "      line = file.readline().split()\n",
        "\n",
        "      print(k)\n",
        "\n",
        "  # собираем негативные данные\n",
        "  k = 0\n",
        "  os.chdir(\"Train data/Negative data\")\n",
        "\n",
        "  for file in glob(\"*.JPG\"):\n",
        "    # Начинаем собирать с заданного индекса\n",
        "    if k < DATASET_START_INDEX:\n",
        "      k += 1\n",
        "      continue\n",
        "    # Условие прерывания при превышении\n",
        "    if k > 68 + DATASET_LIMIT:\n",
        "      break\n",
        "\n",
        "    img = normalize(file)\n",
        "    height, width = img.shape[:2]\n",
        "    x_train.append(img)\n",
        "    y_train.append(np.zeros((height, width)))\n",
        "    k += 1\n",
        "    \n",
        "    print(k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxETmRoYoEpx"
      },
      "source": [
        "# Модель нейросети"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "N0PmN-reoMSh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, SeparableConv2D, MaxPooling2D, Conv2DTranspose, UpSampling2D, add\n",
        "import keras\n",
        "import os\n",
        "\n",
        "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
        "\n",
        "'''\n",
        "Модель взята с официальной документации keras\n",
        "https://keras.io/examples/vision/oxford_pets_image_segmentation/\n",
        "'''\n",
        "\n",
        "def get_model(img_size, num_classes):\n",
        "    inputs = keras.Input(shape=img_size + (1,))\n",
        "\n",
        "    ### [First half of the network: downsampling inputs] ###\n",
        "\n",
        "    # Entry block\n",
        "    x = Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"sigmoid\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "    for filters in [64, 128]:\n",
        "        x = Activation(\"sigmoid\")(x)\n",
        "        x = SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = Activation(\"sigmoid\")(x)\n",
        "        x = SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    ### [Second half of the network: upsampling inputs] ###\n",
        "\n",
        "    for filters in [128, 64, 32]:\n",
        "        x = Activation(\"sigmoid\")(x)\n",
        "        x = Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = Activation(\"sigmoid\")(x)\n",
        "        x = Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = UpSampling2D(2)(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = UpSampling2D(2)(previous_block_activation)\n",
        "        residual = Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "        x = add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    # Add a per-pixel classification layer\n",
        "    outputs = Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYc06PJtolrX"
      },
      "source": [
        "# Обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM8khKACpE-0"
      },
      "source": [
        "- Создаем модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6c13Qw-opQ_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "height, width = x_train[0].shape[:2]\n",
        "\n",
        "# очищаем прошлую модель\n",
        "keras.backend.clear_session()\n",
        "\n",
        "model = get_model((height, width), 1)\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.1),\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[tf.keras.metrics.Accuracy(name=\"accuracy\", dtype=None)])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Преобразуем обучающие данные в пригодный для Tensorflow формат"
      ],
      "metadata": {
        "id": "QLDehGM2pwKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# из массива в np массив\n",
        "x_train = np.array(x_train, dtype=np.int64)\n",
        "y_train = np.array(y_train, dtype=np.int64)\n",
        "\n",
        "# преобразуем в формат Tensorflow\n",
        "y_train = tf.convert_to_tensor(y_train) \n",
        "x_train = tf.convert_to_tensor(x_train)"
      ],
      "metadata": {
        "id": "V1sqc_Zip3Bq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "r4EpItH_se0f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5oNjFr6pPjL"
      },
      "source": [
        "- Обучаем модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwD9rfoypR0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dfabc47-27e1-45c3-da74-26632b103281"
      },
      "outputs": [],
      "source": [
        "model.fit(x=x_train, y=y_train, epochs=EPOCHS, shuffle=True, batch_size=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Сохраняем модель"
      ],
      "metadata": {
        "id": "Es-DsvS1p9Y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"roaddamage_model\")"
      ],
      "metadata": {
        "id": "Y12sYAd2Pkku"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TxETmRoYoEpx"
      ],
      "mount_file_id": "1gggj0-1tQ0zhR3gdPa1Yy9D39qgL0TCZ",
      "authorship_tag": "ABX9TyP4m7gFlipQCJ4AcitxmLTM",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
